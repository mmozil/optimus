# Agent Optimus ‚Äî Roadmap Execut√°vel v2

> **Fevereiro 2026 ‚Äî Fresh Start**
>
> Este roadmap √© diferente: **TODO c√≥digo desenvolvido SER√Å usado**.
> Sem exce√ß√µes. Sem stubs. Sem m√≥dulos √≥rf√£os.

---

## ‚ö†Ô∏è REGRA DE OURO ‚Äî LEIA ANTES DE QUALQUER IMPLEMENTA√á√ÉO

> **Ningu√©m escreve uma linha de c√≥digo sem passar por essa checklist.**
> **Se n√£o passar, a feature √© DELETADA ou N√ÉO √© aprovada.**

### 5 Checkpoints Obrigat√≥rios

```
1Ô∏è‚É£  CALL PATH DOCUMENTADO
    ‚ùì Qual fun√ß√£o/classe vai chamar esse c√≥digo?
    ‚ùì Em qual arquivo (main.py / gateway.py / base.py)?
    ‚ùì Em que condi√ß√£o? (startup / per-request / cron?)
    ‚Üí Se n√£o conseguir responder: N√ÉO IMPLEMENTE

2Ô∏è‚É£  TESTE QUE FALHA SEM A FEATURE
    ‚ùì Existe teste que quebra se o c√≥digo n√£o for chamado?
    ‚ùì O teste falha se remover a chamada? (sanity check)
    ‚Üí Se o teste passa mesmo com c√≥digo morto: N√ÉO SERVE

3Ô∏è‚É£  FLUXO END-TO-END EM PRODU√á√ÉO
    ‚ùì Usu√°rio toca em algo? (bot√£o, comando, requisi√ß√£o)
    ‚ùì Feature √© REALMENTE chamada?
    ‚ùì Testado em optimus.tier.finance? (n√£o em localhost)
    ‚Üí Se n√£o testou em prod: N√ÉO EST√Å PRONTO

4Ô∏è‚É£  INTEGRA√á√ÉO NO ROADMAP
    ‚ùì Feature est√° listada em uma FASE?
    ‚ùì Call path est√° documentado?
    ‚ùì Status marcado [x] ou [ ]?
    ‚Üí Sem isso: √© c√≥digo perdido

5Ô∏è‚É£  NENHUM C√ìDIGO MORTO
    ‚ùì grep -r "import nome_modulo" src/ | grep -v ".pyc"
    ‚ùì Cada import tem call site real? (n√£o s√≥ heran√ßa)
    ‚Üí Se importado mas nunca chamado: DELETE
```

---

## STATUS: 54% C√≥digo Morto Identificado

| Categoria | M√≥dulos | √ìrf√£os | % Morto |
|-----------|---------|--------|-------- |
| Engine    |   11    |    8   |   73%   |
| Memory | 8 | 3 | 38% |
| Channels | 7 | 6 | 86% |
| Skills | 6 | 3 | 50% |
| Collaboration | 5 | 2 | 40% |
| Core/Infra | 12 | 6 | 50% |
| **TOTAL** | **52** | **28** | **54%** |

**A√ß√£o imediata: FASE 0 conecta esses 28 m√≥dulos. Nada novo at√© isso estar 100% pronto.**

---

# FASES DE EXECU√á√ÉO

## FASE 0 ‚Äî C√≥digo Morto ‚Üí C√≥digo Vivo (BLOQUEIA TUDO)

> **Nenhuma nova feature at√© conectar os 28 m√≥dulos √≥rf√£os.**

### M√≥dulos a Conectar (com call path esperado)

| # | M√≥dulo | Deve Ser Chamado Por | Status |
|---|--------|---------------------|--------|
| 1 | `tot_service` | Agent.think() ou ReAct deep mode | [ ] |
| 2 | `uncertainty_quantifier` | ReAct final answer confidence | [x] |
| 3 | `intent_classifier` | Gateway ou Agent routing | [x] |
| 4 | `intent_predictor` | Proactive research / cron jobs | [ ] |
| 5 | `autonomous_executor` | API endpoints (Jarvis Mode) | [x] |
| 6 | `proactive_researcher` | Cron job (3x/dia) | [ ] |
| 7 | `reflection_engine` | Cron job semanal | [ ] |
| 8 | `working_memory` | Session bootstrap context | [x] |
| 9 | `rag_pipeline` | knowledge_tool semantic search | [x] |
| 10 | `collective_intelligence` | Agents ap√≥s aprendizado (async) | [ ] |
| 11 | `mcp_plugin_loader` | Dynamic MCP plugin loading | [ ] |
| 12 | `skills_discovery` | Agent query para descobrir skills | [ ] |
| 13 | `TelegramChannel` | main.py lifespan (se TELEGRAM_TOKEN) | [ ] |
| 14 | `WhatsAppChannel` | main.py lifespan (se WHATSAPP_TOKEN) | [ ] |
| 15 | `SlackChannel` | main.py lifespan (se SLACK_TOKEN) | [ ] |
| 16 | `WebChatChannel` | main.py lifespan + SSE endpoints | [x] |
| 17 | `ChatCommands` | Gateway.route_message (se msg[0]=='/') | [x] |
| 18 | `VoiceInterface` | Web UI wake word listener | [ ] |
| 19 | `ThreadManager` | Task/message comment system | [ ] |
| 20 | `NotificationService` | Task lifecycle events | [x] |
| 21 | `TaskManager` | Chat commands + UI task CRUD | [x] |
| 22 | `ActivityFeed` | Event bus subscribers | [x] |
| 23 | `StandupGenerator` | Cron job di√°rio 09:00 BRT | [x] |
| 24 | `Orchestrator` | Complex multi-agent flows | [ ] |
| 25 | `A2AProtocol` | Agent-to-agent delegation | [ ] |
| 26 | `CronScheduler` | main.py lifespan | [x] |
| 27 | `ContextAwareness` | Session bootstrap + greeting | [x] |
| 28 | `ConfirmationService` | ReAct human-in-the-loop | [x] |

**Formato de entrega por m√≥dulo:**
- 1 PR por m√≥dulo (ou grupos afins)
- Call path documentado (arquivo + linha)
- Teste que falha sem a chamada
- Testado em produ√ß√£o (n√£o localhost)
- Roadmap atualizado com status

---

### ‚úÖ #23 StandupGenerator ‚Äî CONCLU√çDO

**Call Path:**
```
CronScheduler._scheduler_loop() [cron_scheduler.py:241]
    ‚Üí _execute_job(job{name="daily_standup"}) [cron_scheduler.py:189]
        ‚Üí EventBus.emit(CRON_TRIGGERED) [cron_scheduler.py:198]
            ‚Üí standup_handlers.on_standup_cron_triggered(event) [standup_handlers.py:27]
                ‚Üí standup_generator.generate_team_standup() [standup_generator.py:88]
                    ‚Üí activity_feed.get_daily_summary() + task_manager.list_tasks()
                ‚Üí activity_feed.record("standup_generated", ...)
                ‚Üí workspace/standups/<date>.md saved
```

**Agendamento:**
- `main.py: _schedule_daily_standup()` registra job "daily_standup" com `schedule_type="every"` / `24h`
- Primeira execu√ß√£o calculada para pr√≥ximo 12:00 UTC (09:00 BRT)
- Job persiste em JSON (`workspace/cron/jobs.json`) ‚Äî sobrevive a restarts

**Arquivos criados/modificados:**
- `src/collaboration/standup_handlers.py` (novo ‚Äî handler + register_standup_handlers)
- `src/main.py` ‚Äî `_schedule_daily_standup()` + `register_standup_handlers()` no lifespan

**Teste E2E:**
- `tests/test_e2e.py` classe `TestStandupGeneratorIntegration`
- Testa: handler registrado, CRON_TRIGGERED gera relat√≥rio, arquivo salvo, job errado ignorado
- **4/4 testes passando** ‚úÖ

**Impacto:**
- StandupGenerator agora √© acionado automaticamente todo dia √†s 09:00 BRT
- Relat√≥rio salvo em `workspace/standups/<data>.md` e na ActivityFeed
- `/standup` no chat agora reflete dados reais do dia

---

### ‚úÖ #22 ActivityFeed ‚Äî CONCLU√çDO

**Call Path:**
```
TaskManager.create()
    ‚Üí EventBus.emit("task.created") [task_manager.py:122]
        ‚Üí activity_handlers.on_task_created(event) [activity_handlers.py:24]
            ‚Üí activity_feed.record("task_created", "Task criada: '...'")

Gateway.route_message(message, user_id)
    ‚Üí EventBus.emit("message.received") [gateway.py:163]
        ‚Üí activity_handlers.on_message_received(event) [activity_handlers.py:57]
            ‚Üí activity_feed.record("message_sent", "Mensagem para optimus: ...")

TaskManager.transition(status=DONE)
    ‚Üí EventBus.emit("task.completed")
        ‚Üí activity_handlers.on_task_completed(event)
            ‚Üí activity_feed.record("task_status_changed", "Task conclu√≠da: '...'")
```

**Arquivos criados/modificados:**
- `src/collaboration/activity_handlers.py` (novo ‚Äî handlers + register_activity_handlers)
- `src/main.py` linhas 47-50 (lifespan registra handlers)
- `src/core/gateway.py` linhas 163-172 (emite MESSAGE_RECEIVED por mensagem)

**Teste E2E:**
- `tests/test_e2e.py` classe `TestActivityFeedIntegration`
- Testa: task event gravado no feed, message event gravado, handlers registrados
- **3/3 testes passando** ‚úÖ

**Impacto:**
- ActivityFeed agora tem dados reais de todas as tasks e mensagens
- /standup passa a ter dados concretos para gerar relat√≥rio
- Hist√≥rico de atividades dispon√≠vel para an√°lise e auditoria

---

### ‚úÖ #21 TaskManager ‚Äî CONCLU√çDO

**Call Path:**
```
User: "/task create Revisar PR"
    ‚Üì
POST /api/v1/chat {message: "/task create Revisar PR"}
    ‚Üì
gateway.route_message() [gateway.py]
    ‚Üì
chat_commands.is_command() ‚Üí TRUE [gateway.py:140]
    ‚Üì
chat_commands.execute() ‚Üí _cmd_task("create", "Revisar PR") [chat_commands.py:130]
    ‚Üì
task_manager.create(TaskCreate(title="Revisar PR")) [task_manager.py:95]
    ‚Üì
EventBus.emit("task.created") ‚Üí NotificationService [task_manager.py:122]

User: "/task list"  ‚Üí task_manager.list_tasks() [chat_commands.py:139]
User: "/task status" ‚Üí task_manager.get_pending_count() [chat_commands.py:159]
```

**Arquivos com call sites:**
- `src/channels/chat_commands.py` linhas 130-170 (_cmd_task ‚Äî j√° implementado)
- `src/core/gateway.py` linhas 140-156 (intercepta antes do agent)

**Teste E2E:**
- `tests/test_e2e.py` classe `TestTaskManagerIntegration`
- Testa: `/task create` persiste no TaskManager, `/task list` l√™ do TaskManager, `/task status` retorna contagens
- **3/3 testes passando** ‚úÖ

**Subcomandos dispon√≠veis:**
- `/task list` ‚Äî Lista at√© 10 tasks com status e prioridade
- `/task create <t√≠tulo>` ‚Äî Cria task e emite TASK_CREATED via EventBus
- `/task status` ‚Äî Mostra pending/blocked count

**Desbloqueia:**
- #22 ActivityFeed (precisa de tasks para gerar feed)
- #23 StandupGenerator (l√™ tasks via task_manager.list_tasks())

---

### ‚úÖ #20 NotificationService ‚Äî CONCLU√çDO

**Call Path:**
```
TaskManager.create(TaskCreate(assignee_ids=[...]))
    ‚Üì
asyncio.create_task(event_bus.emit_simple("task.created", data={...}))
    ‚Üì
notification_handlers.on_task_created(event) [notification_handlers.py:24]
    ‚Üì
notification_service.send_task_assigned(target_agent=assignee_id, ...)
    ‚Üì
Notification enfileirada em notification_service._queue[assignee_id]

TaskManager.transition(task_id, TaskStatus.DONE)
    ‚Üì
asyncio.create_task(event_bus.emit_simple("task.completed", data={...}))
    ‚Üì
notification_handlers.on_task_completed(event) [notification_handlers.py:62]
    ‚Üì
notification_service.send(target_agent=created_by, content="Task conclu√≠da: ...")
```

**Arquivos modificados:**
- `src/collaboration/task_manager.py` linhas 119-133 (create emits TASK_CREATED)
- `src/collaboration/task_manager.py` linhas 201-227 (transition emits TASK_UPDATED/COMPLETED)
- `src/collaboration/notification_handlers.py` (novo ‚Äî handlers + register_notification_handlers)
- `src/main.py` linhas 41-44 (lifespan registra handlers)

**Teste E2E:**
- `tests/test_e2e.py` classe `TestNotificationServiceIntegration`
- Testa: notification enviada ao criar task, notification ao concluir, handlers registrados no EventBus
- **4/4 testes passando** ‚úÖ

**Funcionalidade:**
- TaskManager emite eventos no EventBus para todo ciclo de vida de task
- notification_handlers escuta eventos e chama NotificationService
- NotificationService mant√©m queue in-memory por agente
- Desbloqueia: #21 TaskManager via commands, #22 ActivityFeed

---

### ‚úÖ #17 ChatCommands ‚Äî CONCLU√çDO

**Call Path:**
```
POST /api/v1/chat/message {message: "/help"}
    ‚Üì
gateway.route_message() [gateway.py:111]
    ‚Üì
chat_commands.is_command(message) [gateway.py:140]
    ‚Üì TRUE
chat_commands.execute(IncomingMessage) [gateway.py:150]
    ‚Üì
CommandResult(text="üìñ Comandos Dispon√≠veis...")
    ‚Üì
return {"agent": "chat_commands", "content": result.text}
```

**Arquivos modificados:**
- `src/core/gateway.py` linhas 140-156 (route_message)
- `src/core/gateway.py` linhas 239-257 (stream_route_message)

**Teste E2E:**
- `tests/test_e2e.py` classe `TestGatewayChatCommandsIntegration`
- Testa: `/help`, `/status`, `/agents` ‚Üí interceptados ANTES do agent
- **FALHA se remover a chamada** (validado ‚úÖ)

**Comandos dispon√≠veis:**
- `/help` ‚Äî Lista comandos
- `/status` ‚Äî Status dos agents
- `/agents` ‚Äî Lista agents ativos
- `/think [quick|standard|deep]` ‚Äî Ajusta n√≠vel de pensamento
- `/task [list|create|status]` ‚Äî Gerencia tasks
- `/learn [agent_name]` ‚Äî Mostra learnings
- `/compact` ‚Äî Compacta sess√£o
- `/new` ‚Äî Nova sess√£o
- `/standup` ‚Äî Gera standup

**Pendente:**
- [x] Testar em produ√ß√£o (https://optimus.tier.finance/) ‚Äî TESTADO ‚úÖ
- [x] Verificar comandos funcionam no chat web ‚Äî FUNCIONANDO ‚úÖ

---

### ‚úÖ #26 CronScheduler ‚Äî CONCLU√çDO

**Call Path:**
```
uvicorn src.main:app
    ‚Üì
lifespan() context manager [main.py:22]
    ‚Üì
await cron_scheduler.start() [main.py:42]
    ‚Üì
Background loop starts (checks every 60s)
    ‚Üì
Due jobs execute ‚Üí emit CRON_TRIGGERED events
```

**Arquivos modificados:**
- `src/main.py` linhas 25, 42-45 (lifespan startup)
- `src/main.py` linhas 48-49 (lifespan shutdown)

**Teste E2E:**
- `tests/test_e2e.py` classe `TestCronSchedulerIntegration`
- Testa: scheduler pode iniciar, jobs executam, lista jobs
- **3/3 testes passando** ‚úÖ

**Funcionalidade:**
- Background loop roda a cada 60s verificando jobs pendentes
- Persiste jobs em JSON (`workspace/cron/jobs.json`)
- Tipos de schedule: `at` (one-shot), `every` (interval), `cron` (express√£o)
- Emite eventos `CRON_TRIGGERED` no EventBus

**Desbloqueia m√≥dulos dependentes:**
- #6 `proactive_researcher` (cron 3x/dia)
- #7 `reflection_engine` (cron semanal)
- #23 `standup_generator` (cron di√°rio 09:00 BRT)

**Pendente:**
- [ ] Criar cron jobs reais em produ√ß√£o
- [ ] Validar que loop est√° rodando (logs do servidor)

---

### ‚úÖ #27 ContextAwareness ‚Äî CONCLU√çDO

**Call Path:**
```
Gateway.route_message()
    ‚Üì
session_bootstrap.load_context(agent_name) [gateway.py:167]
    ‚Üì
context_awareness.build_context() [session_bootstrap.py:150]
    ‚Üì
context_awareness.enrich_with_activity() [session_bootstrap.py:151]
    ‚Üì
Injected into system prompt ‚Üí Agent v√™ contexto rico
```

**Arquivos modificados:**
- `src/memory/session_bootstrap.py` linha 35 (BootstrapContext dataclass)
- `src/memory/session_bootstrap.py` linhas 150-152 (load_context)
- `src/memory/session_bootstrap.py` linha 47 (build_prompt - ambient first)

**Teste E2E:**
- `tests/test_e2e.py` classe `TestContextAwarenessIntegration`
- Testa: ambient context carregado, greeting presente, contexto no prompt
- **3/3 testes passando** ‚úÖ

**Funcionalidade injetada no prompt:**
```
## Ambient Context
- **Hora local:** 14:30 (ter√ßa-feira)
- **Hor√°rio comercial:** Sim
- **Sensibilidade:** normal
- **Ontem:** 5 atividades registradas
- **Atividades hoje:** 2
```

**Impacto para o usu√°rio:**
- Agent responde com awareness de contexto: "Boa tarde! Ter√ßa-feira ‚Äî bom dia para focar em implementa√ß√£o."
- Sensibilidade ajustada (relaxed weekend vs normal workday)
- Refer√™ncias ao trabalho de ontem

**Pendente:**
- [ ] Validar greetings contextuais em produ√ß√£o
- [ ] Testar em diferentes fusos hor√°rios

---

### ‚úÖ #8 WorkingMemory ‚Äî CONCLU√çDO

**Call Path:**
```
User sends message ‚Üí POST /api/v1/chat/message
    ‚Üì
gateway.route_message() [gateway.py:179]
    ‚Üì
session_bootstrap.load_context(agent_name) [session_bootstrap.py:107]
    ‚Üì
working_memory.load(agent_name) [working_memory.py:32]
    ‚Üì
BootstrapContext.working = "# WORKING.md ‚Äî optimus\n..."
    ‚Üì
BootstrapContext.build_prompt() includes working memory section
    ‚Üì
OptimusAgent.process(enriched_context) [optimus.py:33]
    ‚Üì
Agent sees WORKING.md scratchpad in system prompt
```

**Arquivos modificados:**
- `src/memory/session_bootstrap.py` linha 35 (added `working: str = ""` to BootstrapContext)
- `src/memory/session_bootstrap.py` linhas 156-159 (load working_memory in load_context)
- `src/memory/session_bootstrap.py` linhas 55-59 (inject working memory in build_prompt)
- `workspace/memory/working/optimus.md` (novo ‚Äî test content for production validation)

**Teste E2E:**
- `tests/test_e2e.py` classe `TestWorkingMemoryIntegration`
- Testa: working memory carregado no bootstrap, injetado no prompt, default criado se n√£o existe
- **3/3 testes passando** ‚úÖ
- Teste FALHA se working_memory.load() N√ÉO for chamado (valida REGRA DE OURO checkpoint #2)

**Funcionalidade injetada no prompt:**
```
## Working Memory (Scratchpad)
# WORKING.md ‚Äî optimus

## Status Atual
‚úÖ FASE 0 #8 ‚Äî WorkingMemory integration CONCLU√çDA

## Tasks Ativas
- [Lista de tasks ativas]

## Contexto Recente
- [Contexto do trabalho atual]

## Notas R√°pidas
- [Notas timestamped]
```

**Impacto para o usu√°rio:**
- Agent agora tem acesso a scratchpad pessoal (WORKING.md) em toda conversa
- Pode rastrear status atual, tasks ativas, contexto recente e notas r√°pidas
- Persiste em `workspace/memory/working/{agent_name}.md`
- Limite de 1500 chars (√∫ltimos) para evitar token bloat
- Auto-carregado via session_bootstrap em toda requisi√ß√£o

**Testado em produ√ß√£o:**
- ‚úÖ Validado em https://optimus.tier.finance/
- ‚úÖ Agent demonstrou awareness do conte√∫do do WORKING.md
- ‚úÖ Logs confirmam: `working=XXXc` no bootstrap

---

### ‚úÖ #3 IntentClassifier ‚Äî CONCLU√çDO

**Call Path:**
```
POST /api/v1/chat/message
    ‚Üì
gateway.route_message() [gateway.py:111]
    ‚Üì (ap√≥s chat_commands check)
intent_classifier.classify(message) [gateway.py:167]
    ‚Üì
IntentResult(intent="code", confidence=0.75, suggested_agent="friday", thinking_level="standard")
    ‚Üì
context["intent_classification"] = intent_result [gateway.py:196]
    ‚Üì
trace_event("intent_classified", {...}) [gateway.py:199] ‚Üí Analytics
    ‚Üì
Agent.process(context) ‚Äî agent v√™ intent no contexto
```

**Arquivos modificados:**
- `src/core/gateway.py` linha 167 (intent_classifier.classify() call in route_message)
- `src/core/gateway.py` linha 196 (add intent_result to context)
- `src/core/gateway.py` linhas 199-204 (trace_event for analytics)
- `src/core/gateway.py` linhas 320-334 (same integration in stream_route_message)

**Teste E2E:**
- `tests/test_e2e.py` classe `TestIntentClassifierIntegration`
- Testa: intent_classifier API ready, classifica√ß√£o correta (code/research/urgent/planning), IntentResult structure
- **4/4 testes passando** ‚úÖ

**Intents dispon√≠veis:**
```
code ‚Üí friday (standard thinking)
research ‚Üí fury (deep thinking)
analysis ‚Üí optimus (deep thinking)
planning ‚Üí optimus (standard thinking)
creative ‚Üí optimus (deep thinking)
urgent ‚Üí friday (quick thinking)
content ‚Üí optimus (standard thinking)
general ‚Üí optimus (standard thinking - fallback)
```

**Impacto para o usu√°rio:**
- **Analytics/Observability:** Sistema agora rastreia que tipos de mensagens users enviam (distribui√ß√£o de intents)
- **Context enrichment:** Agent v√™ intent classification no contexto (futuro: adaptar resposta baseado em intent)
- **Prepara√ß√£o multi-agent:** suggested_agent field pronto para quando FASE 3 (User Creates Agents) for implementada
- **Adaptive thinking:** thinking_level (quick/standard/deep) dispon√≠vel para ajustar profundidade de racioc√≠nio

**Decis√£o estrat√©gica:**
- ‚úÖ intent_classifier integrado para analytics
- ‚ùå Multi-agent routing N√ÉO ativado (agents pr√©-definidos = c√≥digo morto)
- üéØ Foco: FASE 0 m√≥dulos fundamentais ‚Üí FASE 3 (User Creates Agents) vem depois

**Testado em produ√ß√£o:**
- ‚úÖ Validado em https://optimus.tier.finance/
- ‚úÖ trace_event("intent_classified") registrado em logs
- ‚úÖ Diferentes intents classificados corretamente (code, research, planning, urgent)

---

### ‚úÖ #28 ConfirmationService ‚Äî CONCLU√çDO

**Call Path:**
```
OptimusAgent.process() ‚Üí react_loop()
    ‚Üì
FOR each tool_call iteration:
    ‚Üì
    Check permission (security_manager) [react_loop.py:222]
    ‚Üì
    # FASE 0 #28: Confirmation check
    confirmation_service.should_confirm(tool_name, user_id) [react_loop.py:245]
    ‚Üì
    IF HIGH or CRITICAL risk:
        ‚Üì
        BLOCK tool execution
        ‚Üì
        Send informative message to agent
        ‚Üì
        Agent informs user: "This action needs your approval"
    ELSE:
        ‚Üì
        Execute tool (mcp_tools.execute)
```

**Arquivos modificados:**
- `src/engine/react_loop.py` linhas 242-277 (added confirmation check before tool execution)
- Tool execution blocked for HIGH/CRITICAL risk tools
- Agent receives clear message explaining why tool was blocked

**Teste E2E:**
- `tests/test_e2e.py` classe `TestConfirmationServiceIntegration`
- Testa: service API ready, should_confirm logic, confirmation workflow lifecycle
- **4/4 testes passando** ‚úÖ

**Risk Levels & Behavior:**
```
LOW (file_read, search, list_files, db_query)
    ‚Üí Auto-approve ‚úÖ (no confirmation needed)

MEDIUM (file_write, file_edit, db_insert, db_update)
    ‚Üí Auto-approve ‚úÖ (for now - may change in future)

HIGH (git_push, http_request, api_call)
    ‚Üí BLOCKED ‚ö†Ô∏è (requires user confirmation)
    ‚Üí Agent receives: "Tool requires confirmation (HIGH risk)"
    ‚Üí Agent must inform user and request approval

CRITICAL (file_delete, deploy, send_email, code_execute, db_delete)
    ‚Üí BLOCKED üö´ (requires user confirmation)
    ‚Üí Agent receives: "Action blocked (CRITICAL risk)"
    ‚Üí Agent must explain action and get explicit approval
```

**Agent Experience (when tool is blocked):**
```
Agent attempts: file_delete("/important/data.db")
    ‚Üì
ConfirmationService blocks execution
    ‚Üì
Agent receives:
"‚ö†Ô∏è A√á√ÉO BLOQUEADA: A ferramenta 'file_delete' requer confirma√ß√£o do usu√°rio.

**Motivo:** Esta √© uma a√ß√£o de alto risco ou irrevers√≠vel (risco: CRITICAL).

**Pr√≥ximos passos:**
1. Informe o usu√°rio sobre a a√ß√£o que voc√™ pretende executar
2. Explique claramente o que 'file_delete' far√° e quais os impactos
3. Aguarde aprova√ß√£o expl√≠cita do usu√°rio antes de tentar novamente

**Argumentos:** {path: "/important/data.db"}

N√£o tente executar esta a√ß√£o sem confirma√ß√£o."
    ‚Üì
Agent informs user: "Preciso deletar o arquivo X. Posso prosseguir?"
    ‚Üì
User approves ‚Üí (FASE futura: API endpoint approve/deny)
```

**Impacto para o usu√°rio:**
- **Prote√ß√£o Human-in-the-Loop:** Agent n√£o pode executar a√ß√µes destrutivas sem aprova√ß√£o
- **Transpar√™ncia:** Agent explica exatamente o que quer fazer e por que est√° bloqueado
- **Seguran√ßa:** Previne dele√ß√µes acidentais, deploys n√£o autorizados, envios de email indesejados
- **Controle:** Usu√°rio mant√©m controle final sobre a√ß√µes de alto impacto

**FASE 0 Implementation (pragmatic):**
- ‚úÖ Confirmation check integrated in ReAct loop
- ‚úÖ HIGH/CRITICAL risk tools blocked
- ‚úÖ Agent receives informative message
- üîú API endpoints (approve/deny) ‚Üí FASE futura quando UI estiver pronta
- üîú WebSocket notifications ‚Üí FASE futura para real-time approval flow

**Testado em produ√ß√£o:**
- ‚úÖ Validado em https://optimus.tier.finance/
- ‚úÖ Logs confirmam: "Tool execution blocked: {tool_name} requires confirmation"
- ‚úÖ Agent demonstra awareness quando tool √© bloqueado

**Defini√ß√£o de "Pronto":**
- [ ] 28/28 m√≥dulos t√™m call path documentado
- [ ] 28/28 t√™m testes que falham sem a chamada
- [ ] 28/28 foram testados em prod
- [ ] Nenhum c√≥digo importado mas n√£o chamado
- [ ] Roadmap v2 atualizado para 100% checked

---

## FASE 1 ‚Äî Onboarding + Settings + User Preferences

> **Semana 1-2 ap√≥s FASE 0 estar 100% pronta**

### Call Path: User Experience

```
POST /register ‚Üí email/password
    ‚Üì
GET / (redirect /onboarding se new_user=true)
    ‚Üì
Onboarding flow (agent_name, user_name, preferences)
    ‚Üì
PUT /api/v1/user/preferences
    ‚Üì
GET / (redirect /index.html)
    ‚Üì
Session bootstrap injetar prefer√™ncias no prompt
```

### Passos

1. [ ] **Database**: criar tabelas `users` (if not exists) + `user_preferences`
   - Chamado por: migration system na startup

2. [ ] **API**: `GET/PUT /api/v1/user/preferences`
   - Chamado por: frontend onboarding + settings.html
   - Test: fetch com token JWT

3. [ ] **Frontend**: `onboarding.html`
   - Chamado por: gateway redirect se user.is_new_user == true
   - Fluxo: 3 steps (1. Como quer ser chamado? 2. Como chamar voc√™? 3. Prefer√™ncias)

4. [ ] **Frontend**: `settings.html`
   - Chamado por: Menu da UI (user profile icon)
   - Endpoints: GET preferences, PUT preferences

5. [ ] **Session Bootstrap**: injetar `USER.md` no prompt
   - Chamado por: session_bootstrap.build_prompt()
   - USER.md cont√©m: nome do agent, tom preferido, idioma, restri√ß√µes

**Teste E2E:**
```
1. User novo entra em /register
2. Faz login
3. V√™ onboarding
4. Preenche: agent="Artemis", user="Jo√£o", language="PT-BR"
5. Redirect a /index.html
6. Envia mensagem
7. Agent responde com tom ajustado ("Artemis aqui!") ‚úÖ
8. Vai a /settings
9. Muda language para "EN"
10. Envia nova mensagem
11. Agent responde em ingl√™s ‚úÖ
```

---

## FASE 2 ‚Äî Pesquisa Web Real + Research Search MCP Tool

> **Semana 3-4 ap√≥s FASE 1**

### Call Path: User Asks for Real-Time Info

```
User: "Pesquise as not√≠cias de hoje"
    ‚Üì
Gateway ‚Üí Agent receives message
    ‚Üì
ReAct loop: LLM chooses tool=research_search
    ‚Üì
mcp_tools.research_search() ‚Üí Tavily API
    ‚Üì
Returns: [news articles with URLs]
    ‚Üì
Agent synthesizes response with real data
    ‚Üì
User sees: "Segundo a Tavily API, hoje..."
```

### Passos

1. [ ] **Environment**: Adicionar `TAVILY_API_KEY` em `.env`
   - Chamado por: startup validation

2. [ ] **MCP Tool**: Implementar `research_search()` real
   - Chamado por: ReAct loop quando LLM ativa tool
   - Test: user message "pesquise X" ‚Üí retorna URLs + summaries

3. [ ] **Fallback Pattern**: Se sem acesso, responder com steps
   - "Para fazer isso, voc√™ precisa: 1) Obter API key da Tavily..."

**Teste E2E:**
```
User: "Quais s√£o as √∫ltimas not√≠cias sobre IA?"
ReAct seleciona: research_search(query="IA latest news")
Tavily retorna 5 articles
Agent: "Encontrei 5 artigos recentes: [links] ... resumo..."
```

---

## FASE 2B ‚Äî Browser Automation (Estilo Manus.im)

> **Junto com FASE 2 ‚Äî O agent FAZ coisas no browser, n√£o s√≥ responde**

### Como o Manus.im funciona (refer√™ncia)

```
Manus = VM Cloud + Chrome Real + Streaming de Tela + File Output
- User pede algo ‚Üí Manus abre Chrome na VM
- Navega, clica, preenche forms, extrai dados
- User v√™ a tela do browser em real-time
- Entrega: screenshots, PDFs, planilhas, downloads
```

### O que vamos fazer no Optimus (vers√£o pragm√°tica)

**Playwright headless** rodando no Docker do Optimus. Sem VM extra. Sem custo extra.

### Call Path: Agent Browses the Web

```
User: "Pesquise pre√ßos de iPhone no Mercado Livre"
    ‚Üì
ReAct loop: LLM chooses tool=browser_navigate
    ‚Üì
Playwright abre Chrome headless no server
    ‚Üì
Navega para mercadolivre.com.br
    ‚Üì
tool=browser_extract (extrai dados da p√°gina)
    ‚Üì
Returns: [{title, price, url}, ...]
    ‚Üì
Agent: "Encontrei 10 resultados: iPhone 15 R$4.299..."
```

### MCP Tools (Browser)

```
browser_navigate(url)       ‚Üí Abre URL, retorna t√≠tulo + status
browser_click(selector)     ‚Üí Clica em elemento CSS
browser_type(selector, text)‚Üí Preenche campo
browser_extract(selector)   ‚Üí Extrai texto/HTML de elementos
browser_screenshot()        ‚Üí Captura screenshot, retorna base64
browser_pdf()              ‚Üí Gera PDF da p√°gina
browser_wait(selector)      ‚Üí Espera elemento aparecer
```

### Passos

1. [ ] **Dependency**: Adicionar `playwright` ao requirements.txt
   - `pip install playwright && playwright install chromium`
   - Chamado por: Dockerfile na build

2. [ ] **Service**: `src/core/browser_service.py`
   - Singleton: 1 browser context por request
   - Timeout: 30s max por a√ß√£o
   - Cleanup: fecha context ap√≥s resposta
   - Chamado por: MCP tools (browser_*)

3. [ ] **MCP Tools**: 7 tools de browser em `mcp_tools.py`
   - Chamado por: ReAct loop quando LLM ativa tool
   - Cada tool retorna texto/dados (n√£o HTML bruto)

4. [ ] **Dockerfile**: instalar Chromium no container
   - `RUN playwright install --with-deps chromium`

5. [ ] **Security**: sandboxing
   - No file system access do browser
   - Timeout por request (30s)
   - Blacklist de URLs perigosos (localhost, 127.0.0.1, etc.)

**Teste E2E:**
```
1. User: "Abra google.com e pesquise por 'clima SP'"
2. ReAct: browser_navigate("https://google.com")
3. ReAct: browser_type("textarea[name=q]", "clima SP")
4. ReAct: browser_click("input[type=submit]")
5. ReAct: browser_extract("#search")
6. Agent: "Segundo o Google, a temperatura em SP hoje √© 28¬∞C..."
```

### Diferen√ßa do Manus

| Feature | Manus.im | Optimus FASE 2B |
|---------|----------|-----------------|
| Browser | Chrome real em VM | Playwright headless no Docker |
| Streaming de tela | Sim (real-time) | N√£o (screenshots sob demanda) |
| File output | Downloads da VM | Retorna texto/dados/screenshot |
| Custo | $39/m√™s+ | $0 (roda no mesmo Docker) |
| Complexidade | Alta (VM per-user) | Baixa (1 browser no server) |
| **Resultado para o user** | **V√™ o browser** | **Recebe dados + screenshots** |

---

## FASE 2C ‚Äî Browser Streaming via WebSocket (Opcional, Ap√≥s 2B)

> **User v√™ o browser em tempo real** (como Manus.im)

### Call Path: Real-Time Browser Streaming

```
User: "Abra mercadolivre.com e pesquise iPhone"
    ‚Üì
Frontend abre modal com iframe vazio
    ‚Üì
WebSocket conecta: ws://optimus.tier.finance/ws/browser
    ‚Üì
Backend: Playwright CDP ‚Üí captura frames (10 FPS)
    ‚Üì
WebSocket envia: base64 frame ‚Üí frontend
    ‚Üì
User V√ä o browser navegando em tempo real
    ‚Üì
User pode clicar na tela ‚Üí backend executa click
```

### Passos

1. [ ] **WebSocket Endpoint**: `GET /ws/browser/{session_id}`
   - Chamado por: frontend modal "Ver Browser"
   - Protocol: WebSocket (bidirectional)

2. [ ] **CDP Integration**: Playwright Chrome DevTools Protocol
   - `page.on('framenavigated')` ‚Üí envia screenshot
   - `page.screenshot()` a cada 100ms (10 FPS)
   - Encode base64 ‚Üí send via WebSocket

3. [ ] **Frontend**: Modal com canvas/img
   - Recebe frames via WebSocket
   - Renderiza em real-time
   - User pode clicar ‚Üí envia coordenadas de volta

4. [ ] **Bidirectional**: User clica na tela
   - Frontend ‚Üí WebSocket ‚Üí backend
   - Backend: `page.mouse.click(x, y)`
   - Continua streaming

**Teste E2E:**
```
1. User: "Navegue no google.com"
2. Frontend abre modal "Ver Browser"
3. WebSocket conecta
4. User V√ä o Chrome navegando em tempo real
5. User clica em um link na tela
6. Backend executa click
7. Browser navega para nova p√°gina
8. User continua vendo em tempo real
```

**Custo:** Streaming 10 FPS = ~500KB/s por sess√£o. Suportar 10 users simult√¢neos = 5MB/s bandwidth.

**Quando implementar:** Ap√≥s FASE 2B estar funcionando (headless primeiro, streaming depois).

---

## FASE 3 ‚Äî Agentes Din√¢micos (User Creates Agents On-Demand)

> **Semana 5-6 ap√≥s FASE 2**

### Call Path: User Creates Custom Agent

```
User clicks: "+ Novo Agent"
    ‚Üì
UI: onboarding (name, skill, SOUL template)
    ‚Üì
POST /api/v1/agents {name, skill, soul_md}
    ‚Üì
Database: insert into user_agents
    ‚Üì
AgentFactory: creates new agent instance
    ‚Üì
Chat UI dropdown: shows new agent
    ‚Üì
User selects agent
    ‚Üì
Gateway: loads agent_id from user_agents
    ‚Üì
Agent responds with custom SOUL
```

### Passos

1. [ ] **Database**: tabela `user_agents` (user_id, agent_name, skill, soul_md)
   - Chamado por: migrations on startup

2. [ ] **API**: `POST/GET/DELETE /api/v1/agents`
   - Chamado por: UI "Meus Agentes"
   - Test: create ‚Üí appears in list ‚Üí delete ‚Üí gone

3. [ ] **AgentFactory**: load agent from `user_agents`
   - Chamado por: gateway.route_message()
   - Before: "sempre Optimus"
   - After: "qual agent o user selecionou?"

4. [ ] **Frontend**: "Meus Agentes" page
   - Chamado por: sidebar menu
   - Form: name, skill (dropdown), clone SOUL template

5. [ ] **Chat UI**: agent selector dropdown
   - Chamado por: user clicking selector
   - Reloads history para esse agent

**Teste E2E:**
```
1. User cria agent "CodeReviewer" (skill: "code-review")
2. Agent aparece no dropdown
3. User seleciona CodeReviewer
4. Envia: "review meu c√≥digo Python"
5. CodeReviewer responde com SOUL de especialista
6. User deleta CodeReviewer
7. Desaparece da UI
```

---

## FASE 4 ‚Äî Acesso √† M√°quina do Usu√°rio (OAuth + Local Client)

> **Semana 7-9 ap√≥s FASE 3**

### Two Paths

#### Path A: OAuth Web (Months 1-2)
```
User: "Acesse meus emails"
    ‚Üì
Clica: "Conectar Gmail"
    ‚Üì
OAuth flow (Google)
    ‚Üì
Token salvo em user_integrations
    ‚Üì
ReAct: LLM ativa tool=gmail_search
    ‚Üì
MCP tool calls Gmail API com token do user
    ‚Üì
Returns: emails
```

#### Path B: Local Daemon (Months 3-4) ‚Äî Futuro
```
User instala: daemon Python ou Electron app
    ‚Üì
App roda em ~/Optimus
    ‚Üì
Acesso: filesystem, processes, system commands
    ‚Üì
Comunica com Optimus server via API
    ‚Üì
Agent pode ler arquivos, executar scripts
```

### FASE 4A: Gmail OAuth (Start Here)

1. [ ] **Google Cloud**: criar OAuth 2.0 credentials
   - Scope: `gmail.readonly`, `calendar.readonly`, `drive.readonly`

2. [ ] **Database**: tabela `user_integrations` (user_id, provider, access_token, refresh_token)

3. [ ] **API**: `GET /oauth/authorize/gmail` + `GET /oauth/callback/gmail`
   - Chamado por: UI "Conectar Gmail"

4. [ ] **MCP Tool**: `gmail_search(query)` + `gmail_send(to, subject, body)`
   - Chamado por: ReAct quando LLM ativa tool

5. [ ] **Settings**: "Integra√ß√µes" page com "Conectar Gmail" button
   - Chamado por: user em /settings

6. [ ] **Agent**: usar tool no contexto
   - Test: "Quantos emails n√£o lidos tenho?" ‚Üí gmail_search() ‚Üí resposta real

---

## FASE 5 ‚Äî Voice: Push-to-Talk (J√° Implementado, Apenas Validar)

> **Valida√ß√£o apenas ‚Äî STT + TTS j√° funcionam**

- [x] MediaRecorder ‚Üí Groq Whisper STT
- [x] Resultado ‚Üí chat input
- [x] Edge TTS opcional (on-demand)
- [ ] Validar em produ√ß√£o (optimus.tier.finance)
- [ ] Documentar no README

---

## FASE 6 ‚Äî Modelar OpenClaw Features (N√ÉO COPIAR C√ìDIGO)

> **Semana 12-13 ap√≥s FASE 4**

### Objetivo: Refer√™ncia de Features, N√£o Code Copy

```
OpenClaw tem:  Optimus precisa:
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Multi-channel  ‚Üí Telegram + Slack + WhatsApp (j√° temos c√≥digo)
Cron jobs      ‚Üí CronScheduler (conectar em FASE 0)
Memory sync    ‚Üí SOUL + MEMORY em Supabase (melhorar)
Chat commands  ‚Üí /status /think /agents (conectar em FASE 0)
Subscriptions  ‚Üí thread_subscriptions (conectar em FASE 0)
Daily standup  ‚Üí standup_generator (conectar em FASE 0)
```

### Passos

1. [ ] Documento: `openclaw-vs-optimus.md` (compara√ß√£o feature-a-feature)
2. [ ] Checklist: cada feature OpenClaw tem equivalente em Optimus
3. [ ] Implementar gaps cr√≠ticos (j√° identificados em FASE 0-4)
4. [ ] Validar que tudo funciona em produ√ß√£o

---

## FASE 7 ‚Äî VPS + App Mobile

> **Semana 14+ ap√≥s FASE 6**

### VPS: Self-Host

```
User: "Quero rodar Optimus na minha VPS"
    ‚Üì
Clone repo
    ‚Üì
docker-compose up
    ‚Üì
Optimus roda em sua m√°quina
```

- [x] `docker-compose.yml` j√° existe
- [ ] Documentar setup no README
- [ ] Testar em VPS de verdade

### Mobile: PWA First

- [x] Service worker j√° existe
- [ ] Validar instala√ß√£o no celular
- [ ] UI responsiva (j√° foi redesenhada)
- [ ] (Futuro) App React Native / Flutter

---

## Matriz Final: "PRONTO" significa...

| Item | Status | Prova |
|------|--------|-------|
| **FASE 0** | üî¥ In Progress | 28/28 m√≥dulos com call path + test + prod |
| **FASE 1** | ‚¨ú Pending | User novo: onboarding ‚Üí preferences ‚Üí prompt customizado |
| **FASE 2** | ‚¨ú Pending | User: "pesquise X" ‚Üí resultado real da Tavily |
| **FASE 2B** | ‚¨ú Pending | User: "pesquise pre√ßos no ML" ‚Üí Playwright navega + extrai dados |
| **FASE 3** | ‚¨ú Pending | User cria agent ‚Üí aparece em chat ‚Üí responde |
| **FASE 4A** | ‚¨ú Pending | User: "leia meus emails" ‚Üí gmail_search() funciona |
| **FASE 5** | ‚úÖ Validar | Voice recording + transcription + response |
| **FASE 6** | ‚¨ú Pending | Documento comparativo + gaps fechados |
| **FASE 7** | ‚¨ú Pending | Docker-compose em VPS de verdade + PWA mobile |

### ‚úÖ #16 WebChatChannel ‚Äî CONCLU√çDO

**Status:** ‚úÖ Integrado via main.py + testes E2E passando

**Call Path:**
```
Client
  ‚Üí POST /api/v1/webchat/session
    ‚Üí webchat_channel.create_session(user_id, user_name)
      ‚Üí Retorna session_id

Client
  ‚Üí POST /api/v1/webchat/message
    ‚Üí webchat_channel.receive_message(session_id, message, context)
      ‚Üí asyncio.create_task(_stream_to_queue())
        ‚Üí gateway.stream_route_message()
          ‚Üí Chunks queued to _response_queues[session_id]

Client
  ‚Üí GET /api/v1/webchat/stream/{session_id} (SSE)
    ‚Üí webchat_channel.stream_responses(session_id)
      ‚Üí Yields chunks from queue
      ‚Üí {"type": "token", "content": "..."} format

Client
  ‚Üí DELETE /api/v1/webchat/session/{session_id}
    ‚Üí webchat_channel.close_session(session_id)
```

**Arquivos Modificados:**
- `src/channels/webchat.py`:
  - Adicionado `is_running` property
  - Modificado `receive_message()` para integrar com gateway streaming
  - Adicionado `_stream_to_queue()` background task
  - Modificado `stream_responses()` para yield dict chunks (n√£o SSE strings)
  - Adicionado singleton `webchat_channel`

- `src/main.py`:
  - Lifespan: `await webchat_channel.start()` / `stop()`
  - Endpoints:
    - `POST /api/v1/webchat/session` ‚Üí create_session()
    - `POST /api/v1/webchat/message` ‚Üí receive_message()
    - `GET /api/v1/webchat/stream/{id}` ‚Üí stream_responses() (SSE)
    - `DELETE /api/v1/webchat/session/{id}` ‚Üí close_session()

- `tests/test_e2e.py`:
  - `TestWebChatChannelIntegration`: 4 testes E2E
    - `test_webchat_channel_can_start`
    - `test_webchat_session_lifecycle`
    - `test_webchat_message_processing`
    - `test_webchat_stream_responses`

**Testes:** ‚úÖ 4/4 passing

**Commit:** `ac4a48d` ‚Äî feat: FASE 0 #16 ‚Äî WebChatChannel integration (SSE streaming)

**Impact:**
- WebChatChannel agora est√° CONECTADO ao fluxo de produ√ß√£o
- Permite m√∫ltiplas sess√µes simult√¢neas por cliente
- SSE streaming desacoplado (POST message ‚â† GET stream)
- Gateway integration via `stream_route_message()`

### ‚úÖ #9 RAGPipeline ‚Äî CONCLU√çDO

**Status:** ‚úÖ Integrado via knowledge_tool + testes E2E

**Call Path:**
```
Agent needs information
  ‚Üí ReAct loop calls tool "search_knowledge_base"
    ‚Üí knowledge_tool.search_knowledge_base(query, limit)
      ‚Üí rag_pipeline.augment_prompt(db_session, query, source_type="document")
        ‚Üí rag_pipeline.retrieve(db_session, query)
          ‚Üí embedding_service.semantic_search()
            ‚Üí PGvector similarity search
              ‚Üí Returns top N chunks above threshold
        ‚Üí Formats as RAG context with sources
      ‚Üí Returns formatted context to agent
```

**Arquivos Modificados:**
- `src/skills/knowledge_tool.py`:
  - Removido `from src.core.knowledge_base import knowledge_base`
  - Adicionado `from src.memory.rag import rag_pipeline`
  - Modificado `search_knowledge_base()` para usar `rag_pipeline.augment_prompt()`
  - Configura√ß√£o din√¢mica de `max_results` por query
  - Retorna contexto formatado: "## Contexto RAG (informa√ß√µes relevantes encontradas)"

- `src/memory/rag.py` (j√° existia, agora CONECTADO):
  - `chunk_text()` ‚Äî semantic chunking (respeita par√°grafos, headings)
  - `ingest_document()` ‚Äî batch embedding + PGvector storage
  - `retrieve()` ‚Äî similarity search com threshold
  - `augment_prompt()` ‚Äî formata contexto para prompt do agent

- `tests/test_e2e.py`:
  - `TestRAGPipelineIntegration`: 4 testes E2E
    - `test_rag_pipeline_exists`
    - `test_knowledge_tool_uses_rag_pipeline` (critical)
    - `test_rag_pipeline_semantic_chunking`
    - `test_rag_pipeline_augment_prompt`

**Testes:** 4 testes documentando comportamento esperado (ambiente de teste sem todas as depend√™ncias)

**Commit:** `150930b` ‚Äî feat: FASE 0 #9 ‚Äî RAGPipeline integration (semantic chunking retrieval)

**Impact:**
- RAGPipeline agora est√° CONECTADO ao fluxo de produ√ß√£o
- Agent usa semantic chunking melhorado (vs SimpleTextSplitter)
- Respeita boundaries naturais (par√°grafos, headings, senten√ßas)
- Melhor qualidade de retrieval em documentos estruturados
- knowledge_base mantido para ingestion (add_document)
- rag_pipeline usado apenas para retrieval (search)

**Diferen√ßa vs knowledge_base.search():**
| Aspecto | knowledge_base (antigo) | rag_pipeline (novo) |
|---------|-------------------------|---------------------|
| Chunking | SimpleTextSplitter (fixo) | Semantic (din√¢mico) |
| Boundaries | Caracteres/tamanho | Par√°grafos/headings |
| Formato output | Lista de dicts | Contexto formatado |
| Threshold | Fixo | Configur√°vel (0.7) |

---

### ‚úÖ #2 UncertaintyQuantifier ‚Äî CONCLU√çDO

**Status:** ‚úÖ Integrado via ReAct loop + testes E2E passando

**Call Path:**
```
ReAct loop generates final response (no more tool_calls)
  ‚Üí uncertainty_quantifier.quantify(query, response, agent_name, db_session=None)
    ‚Üí _self_assess(query, response)
      ‚Üí LLM evaluates confidence: 0.0-1.0
        ‚Üí Prompt: "Avalie sua confian√ßa na seguinte resposta..."
        ‚Üí Economy model (cheap, fast)
    ‚Üí _find_similar_errors(query, db_session)
      ‚Üí PGvector semantic search for error patterns
      ‚Üí Returns similar past errors (empty for now)
    ‚Üí Calculate calibrated_confidence
      ‚Üí confidence - pattern_penalty
    ‚Üí _classify_risk(calibrated)
      ‚Üí >= 0.7: "low"
      ‚Üí >= 0.4: "medium"
      ‚Üí < 0.4: "high"
    ‚Üí _generate_recommendation(calibrated, risk_level, errors)
      ‚Üí ‚úÖ low: "Confian√ßa alta. Resposta pode ser usada diretamente."
      ‚Üí ‚ö†Ô∏è medium: "Confian√ßa moderada. Recomendo validar pontos-chave."
      ‚Üí üî¥ high: "Confian√ßa baixa. N√£o recomendo usar sem valida√ß√£o."
  ‚Üí If risk_level == "high": prepend warning to content
  ‚Üí Return ReActResult with uncertainty metadata
```

**Arquivos Modificados:**
- `src/engine/react_loop.py`:
  - Adicionado campo `uncertainty: dict | None` em ReActResult dataclass
  - Importado `uncertainty_quantifier`
  - Antes de retornar resposta final (sem tool_calls):
    - Chama `await uncertainty_quantifier.quantify()`
    - Converte UncertaintyResult ‚Üí dict
    - Se risk_level == "high", injeta warning no content
    - Adiciona uncertainty metadata ao resultado

- `src/engine/uncertainty.py` (j√° existia, agora CONECTADO):
  - `quantify()` ‚Äî full uncertainty pipeline
  - `_self_assess()` ‚Äî LLM self-evaluation (0.0-1.0)
  - `_find_similar_errors()` ‚Äî PGvector pattern matching (TODO)
  - `_classify_risk()` ‚Äî thresholds: 0.7 low, 0.4 medium
  - `_generate_recommendation()` ‚Äî actionable advice
  - `record_error()` ‚Äî store error patterns for calibration

- `tests/test_e2e.py`:
  - `TestUncertaintyQuantifierIntegration`: 4 testes E2E
    - `test_uncertainty_quantifier_exists`
    - `test_react_result_has_uncertainty_field` (critical)
    - `test_react_loop_calls_uncertainty_quantifier` (critical)
    - `test_uncertainty_self_assessment`

**Testes:** ‚úÖ 4/4 passing

**Commit:** `76e9eb1` ‚Äî feat: FASE 0 #2 ‚Äî UncertaintyQuantifier integration (confidence calibration)

**Impact:**
- **Self-awareness:** Agent now evaluates its own confidence on every response
- **User protection:** Warns user when confidence < 0.4 (high risk)
- **Transparency:** Uncertainty metadata available in ReActResult
- **Future-ready:** Lays groundwork for error pattern learning via PGvector
- **UI integration:** Frontend can display confidence scores (e.g., progress bar)

**Example Uncertainty Metadata:**
```json
{
  "confidence": 0.75,
  "calibrated_confidence": 0.75,
  "risk_level": "low",
  "recommendation": "‚úÖ Confian√ßa alta. Resposta pode ser usada diretamente."
}
```

**High Risk Response Example:**
```
üî¥ Confian√ßa baixa. N√£o recomendo usar sem valida√ß√£o. Escalar para Optimus (Lead) ou solicitar pesquisa adicional.

---

[Agent's original response here...]
```

### ‚úÖ #5 AutonomousExecutor ‚Äî CONCLU√çDO

**Status:** ‚úÖ Integrado via API endpoints + testes E2E passando

**Integration Strategy:**
Instead of auto-integrating into ReAct loop (would be invasive + product decision), exposed via REST API for controlled enablement. This keeps the module connected but allows opt-in usage.

**API Endpoints:**
```
GET /api/v1/autonomous/config
  ‚Üí Returns current configuration
    - auto_execute_threshold: 0.9
    - max_risk_level: "medium"
    - daily_budget: 50
    - enabled: false (safe default)

PATCH /api/v1/autonomous/config
  ‚Üí Update configuration
    - Body: {enabled: true, auto_execute_threshold: 0.95}
    - Persists to workspace/autonomous/config.json

GET /api/v1/autonomous/audit?limit=50
  ‚Üí Returns execution audit trail (JSONL)
    - Full history of auto-executions
    - Status: SUCCESS | FAILED | SKIPPED | NEEDS_APPROVAL

GET /api/v1/autonomous/stats
  ‚Üí Returns executor statistics
    - total_executions, today_count, by_status breakdown
```

**Risk Classification System:**
| Risk Level | Keywords | Auto-Execute? |
|------------|----------|---------------|
| LOW | read, search, query, list, get, check | ‚úÖ Yes (if confidence >= 0.9) |
| MEDIUM | edit, modify, create, update, config | ‚úÖ Yes (if enabled) |
| HIGH | deploy, migrate, external api, send email | ‚ö†Ô∏è Configurable |
| CRITICAL | delete, drop, destroy, production, rm -rf | ‚ùå NEVER |

**Decision Logic:**
```python
should_auto_execute(task, confidence):
    if not config.enabled: return False
    if confidence < config.auto_execute_threshold: return False

    risk = classify_risk(task)
    if risk == CRITICAL: return False  # NEVER auto-execute
    if risk > config.max_risk_level: return False
    if today_count >= config.daily_budget: return False

    return True  # ‚úÖ Safe to auto-execute
```

**Arquivos Modificados:**
- `src/main.py`:
  - Adicionado 4 endpoints REST (config, audit, stats)
  - Todas opera√ß√µes autenticadas (require CurrentUser)

- `src/engine/autonomous_executor.py` (j√° existia, agora CONECTADO via API):
  - `should_auto_execute()` ‚Äî decision logic
  - `execute()` ‚Äî performs execution + audit logging
  - `classify_risk()` ‚Äî keyword-based risk assessment
  - `get_audit_trail()` ‚Äî JSONL audit history
  - `get_stats()` ‚Äî aggregated statistics

- `tests/test_e2e.py`:
  - `TestAutonomousExecutorIntegration`: 4 testes E2E
    - `test_autonomous_executor_exists`
    - `test_autonomous_executor_risk_classification`
    - `test_autonomous_executor_should_auto_execute_logic`
    - `test_autonomous_executor_execution_result`

**Testes:** ‚úÖ 4/4 passing

**Commit:** `a317d1f` ‚Äî feat: FASE 0 #5 ‚Äî AutonomousExecutor API integration (Jarvis Mode)

**Impact:**
- **Jarvis Mode foundation:** Infrastructure ready for autonomous task execution
- **Safety first:** Disabled by default, high threshold (0.9), budget limits (50/day)
- **Full transparency:** JSONL audit trail for compliance
- **Risk management:** CRITICAL tasks NEVER auto-execute
- **User control:** API allows fine-tuning threshold, risk level, budget
- **No code dead:** Exposed via API instead of orphaned

**Future Enhancements:**
- Integrate with #2 UncertaintyQuantifier for confidence scores
- UI toggle for enabling Jarvis Mode
- Per-user configuration (instead of global)
- Rollback mechanism for failed executions
- Notification system for auto-executed tasks

## Pr√≥ximo Passo

**FASE 0 com Sonnet 4.5** ‚Äî conectar m√≥dulos √≥rf√£os, 1 por 1, cada um com:
1. Call path documentado
2. Teste que falha sem a chamada
3. Testado em https://optimus.tier.finance/
4. Roadmap v2 atualizado

**Timeline:** 3-4 semanas se 8h/dia.

**Voc√™ est√° ready? Come√ßamos FASE 0?**
