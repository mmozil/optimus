# AgentOptimus ‚Äî Roadmap Unificado

> **√öltima atualiza√ß√£o:** 2026-02-19
> **Fonte:** Consolida√ß√£o de `planning-optimus.md`, `Roadmap-Optimus.md`, `roadmap-optimus-v2.md`, `agent-claude.md`, `prompt-avancado.md`, `Prompt-COT.md`
> **Regra:** Toda implementa√ß√£o DEVE seguir a Regra de Ouro + Regra de Blindagem abaixo.

---

## REGRA DE OURO ‚Äî Obrigat√≥rio em TODA implementa√ß√£o

Nenhuma feature √© implementada sem passar nos 5 checkpoints:

| # | Checkpoint | Pergunta-chave |
|---|-----------|----------------|
| 1 | **Call Path Documentado** | Qual fun√ß√£o chama esse c√≥digo? Em qual arquivo? Em que condi√ß√£o (startup/request/cron)? |
| 2 | **Teste que Falha** | Existe teste E2E que quebra se o c√≥digo n√£o for chamado? |
| 3 | **Implementa√ß√£o Integrada** | O c√≥digo est√° conectado ao fluxo real (gateway/react_loop/main.py)? |
| 4 | **Testado em Produ√ß√£o** | Validado em https://optimus.tier.finance com evid√™ncia? |
| 5 | **Roadmap Atualizado** | Status marcado neste documento com data e evid√™ncia? |

**Se algum checkpoint falhar ‚Üí feature N√ÉO √© entregue.**

---

## REGRA DE BLINDAGEM ‚Äî Prote√ß√£o contra regress√£o

Toda altera√ß√£o DEVE garantir que n√£o quebra funcionalidades existentes:

| # | Regra | Como |
|---|-------|------|
| 1 | **Testes existentes passam** | Rodar `pytest tests/test_e2e.py` antes e depois da mudan√ßa |
| 2 | **Imports n√£o quebram** | Verificar que nenhum import existente foi removido ou renomeado sem atualizar chamadores |
| 3 | **Contratos de API preservados** | Endpoints existentes mant√™m mesma assinatura (query params, body, response) |
| 4 | **Fallback graceful** | Se novo c√≥digo falhar, o fluxo anterior continua funcionando (try/except com log) |
| 5 | **Sem efeitos colaterais** | Mudan√ßa em m√≥dulo X n√£o altera comportamento de m√≥dulo Y sem documenta√ß√£o expl√≠cita |

---

## Estado Atual ‚Äî O que FUNCIONA em produ√ß√£o

- [x] Chat via Gemini (ReAct loop + tool calling + fallback)
- [x] Login/Registro JWT + Auth pages
- [x] Hist√≥rico de mensagens (PostgreSQL)
- [x] STT ‚Äî Groq Whisper (whisper-large-v3)
- [x] TTS ‚Äî Edge TTS (pt-BR-AntonioNeural)
- [x] Multi-model failover (Gemini Flash ‚Üí Pro ‚Üí GPT-4o)
- [x] SOUL.md + MEMORY.md no system prompt
- [x] Emotional Adapter (sentimento ‚Üí tom do prompt)
- [x] Planning Engine (decomposi√ß√£o de tarefas)
- [x] Auto-Journal (aprendizado p√≥s-resposta)
- [x] Persona Selector (persona por intent)
- [x] Agent Factory + BaseAgent
- [x] Session Manager + Session Compacting
- [x] Cost Tracker
- [x] Deploy CI/CD (Push ‚Üí Coolify ‚Üí Docker)
- [‚ö†Ô∏è] Web Research ‚Äî stub (`research_search` retorna mock, Tavily N√ÉO integrado ‚Äî ver FASE 26)
- [x] Browser Automation (Playwright/CDP)
- [x] Dynamic Agents (cria√ß√£o sob demanda)
- [x] Google OAuth + IMAP/SMTP (email)
- [x] Memory Sync to DB
- [x] Apple iCloud integration
- [x] Multimodal Input (imagens, √°udio, PDF, CSV)
- [x] Onboarding + Settings page
- [x] A2A Protocol (API REST)
- [x] Collective Intelligence (cross-agent learning)
- [‚ö†Ô∏è] ToT Engine ‚Äî parcial (pre-reasoning injetado em queries complexas, mas `think()` completo nunca chamado em conversa real ‚Äî ver FASE 25)
- [‚ö†Ô∏è] UncertaintyQuantifier ‚Äî parcial (üî¥ warning via heur√≠stica simples, quantifier real nunca chamado ‚Äî ver FASE 25)
- [x] Chat Commands (10 comandos: /status /help /agents /task /learn /think /compact /new /standup /cron)
- [x] Thread Manager (task ‚Üí thread ‚Üí subscribe ‚Üí @mentions)
- [x] Notification Service (send ‚Üí polling REST ‚Üí toast no frontend)
- [x] Working Memory (WORKING.md por agent no contexto)
- [x] Context Awareness (hora/dia/sauda√ß√£o no prompt)
- [x] Intent Routing (smart agent routing por intent)
- [x] Audit Trail (react_steps persistidos em audit_log ‚Üí painel debug no frontend)
- [x] Embeddings Collective Intelligence (PGvector coseno, semantic=True por padr√£o, batch index)

---

## FASE 10 ‚Äî Chat Commands & Thread System ‚úÖ CONCLU√çDA (2026-02-19)

**Objetivo:** Conectar `chat_commands.py`, `thread_manager.py` e `notification_service.py` ao fluxo principal.

- [x] **10.1** `/status`, `/help`, `/agents`, `/task`, `/learn`, `/cron`, `/standup` ‚Äî J√Å INTEGRADO
  - Call path: `gateway.route_message()` linha 163 ‚Üí `chat_commands.is_command()` ‚Üí `execute()`
- [x] **10.2** thread_manager conectado ao `/task create`
  - Call path: `_cmd_task("create")` ‚Üí `task_manager.create()` ‚Üí `thread_manager.subscribe(creator)` + `post_message()`
- [x] **10.3** notification_service ‚Üí polling REST + frontend toast
  - API: `GET /api/v1/notifications` + `POST /api/v1/notifications/{id}/read`
  - API: `GET /api/v1/tasks` + `GET /api/v1/tasks/{id}/thread`
  - Frontend: polling a cada 30s ‚Üí `showToast()` ‚Üí auto-dismiss 6s + click para dispensar
- [x] **10.4** Testes E2E ‚Äî `TestFase10ChatCommandsAndNotifications` (9 testes)
  - `/help`, `/status`, `/task create`, `notification_service`, `thread_manager`, `gateway intercept`
- [ ] **10.5** Testar em produ√ß√£o (https://optimus.tier.finance)

---

## FASE 11 ‚Äî Channels (Telegram + WhatsApp)

**Objetivo:** Ativar pelo menos 1 canal al√©m do web.
**Por qu√™:** 86% do c√≥digo de channels √© morto. Telegram √© o mais vi√°vel (sem depend√™ncia externa).

- [ ] **11.1** Telegram ‚Äî configurar bot token + webhook
  - Call path: `main.py startup` ‚Üí `telegram.start()` ‚Üí recebe update ‚Üí `gateway.route_message(channel="telegram")`
- [ ] **11.2** Telegram ‚Äî testar envio e recebimento de mensagem em produ√ß√£o
- [ ] **11.3** WhatsApp (Evolution API) ‚Äî avaliar se vale o custo de deploy separado
  - Decis√£o: s√≥ implementar se houver demanda real do usu√°rio
- [ ] **11.4** Testes E2E para channel routing

---

## FASE 12 ‚Äî Audit Trail & Observabilidade ‚úÖ CONCLU√çDA (2026-02-19)

**Objetivo:** Persistir react_steps, tool calls e decis√µes para debug e melhoria cont√≠nua.
**Por qu√™:** `react_steps` s√£o computados no ReAct loop mas nunca salvos. Sem audit trail, n√£o h√° como debugar respostas ruins.
**Ref:** `agent-claude.md` se√ß√£o "Audit Trail"

- [x] **12.1** Criar tabela `audit_log` (session_id, agent, step_type, content, timestamp)
  - `migrations/022_audit_log.sql` + `src/core/audit_service.py`
- [x] **12.2** Salvar react_steps no audit_log ap√≥s cada resposta
  - Call path: `gateway.route_message()` ‚Üí `asyncio.create_task(audit_service.save(session_id, agent, steps, usage))`
  - `conversation_id` retornado no resultado para o frontend consultar
- [x] **12.3** Endpoints REST:
  - `GET /api/v1/audit/{session_id}` ‚Äî steps de uma sess√£o
  - `GET /api/v1/audit` ‚Äî √∫ltimas sess√µes com contagem
- [x] **12.4** Painel colaps√°vel no frontend (bot√£o "üîç Audit" no canto inferior direito)
  - Mostra step_type (reason/act/observe/summary) com √≠cones e dura√ß√£o
  - Atualiza automaticamente ap√≥s cada mensagem
- [x] **12.5** Testes E2E: `TestFase12AuditTrail` (6 passed, 1 skipped sem DB local)
- [ ] **12.6** Testar em produ√ß√£o (https://optimus.tier.finance)

---

## FASE 13 ‚Äî Embeddings na Collective Intelligence ‚úÖ CONCLU√çDA (2026-02-19)

**Objetivo:** Substituir busca por substring por busca sem√¢ntica (PGvector) no knowledge sharing.
**Por qu√™:** `collective_intelligence.py` usava `in` (substring) para buscar. Com >100 entries, precis√£o cai drasticamente.
**Ref:** `agent-claude.md` se√ß√£o "Embeddings"

- [x] **13.1** Embedding ao salvar knowledge entry
  - Call path: `collective_intelligence.async_share()` ‚Üí `embedding_service.embed_text()` ‚Üí `store_embedding()` ‚Üí PGvector
  - J√° chamado desde FASE 11: `gateway._auto_share_learning()` usa `async_share()`
- [x] **13.2** Busca por similaridade coseno (padr√£o agora)
  - `query_semantic()` usa `embedding_service.semantic_search()` ‚Üí `SELECT ... ORDER BY embedding <=> query_vec`
  - **`semantic=True` agora √© o DEFAULT** em `GET /api/v1/knowledge/query`
  - Fallback autom√°tico para keyword se PGvector indispon√≠vel
- [x] **13.3** Batch migration de entries existentes
  - `POST /api/v1/knowledge/index` ‚Üí `collective_intelligence.index_knowledge()`
- [x] **13.4** Testes E2E: `TestFase13Embeddings` (9 passed, 2 skipped sem fastapi local)
- [x] **13.5** Testado em produ√ß√£o ‚úÖ (2026-02-19)
  - "como validar dados em API" ‚Üí FastAPI/Pydantic (similarity=0.86)
  - "busca semantica postgres" ‚Üí PGvector entry (similarity>0.5)
  - Keyword fallback (`semantic=false`) continua funcional
  - Bugs corrigidos: SDK google-genai, modelo gemini-embedding-001, CAST vector, json.dumps metadata

---

## FASE 14 ‚Äî Temporal Memory & Decay ‚úÖ CONCLU√çDA

**Objetivo:** Implementar decaimento temporal na mem√≥ria para que conhecimento obsoleto perca relev√¢ncia.
**Por qu√™:** Mem√≥ria acumula sem limite. Informa√ß√µes de 6 meses atr√°s t√™m mesmo peso que de hoje.
**Ref:** `agent-claude.md` se√ß√£o "Temporal Decay"

- [x] **14.1** Adicionar `last_accessed_at`, `access_count` e `archived` na tabela `embeddings`
  - Migration: `migrations/023_embeddings_temporal.sql`
- [x] **14.2** Score de relev√¢ncia: `similarity * recency_factor * access_factor`
  - `recency_factor = exp(-LAMBDA * days_since_access)` (LAMBDA=0.01, half-life~69 dias)
  - `access_factor = min(2.0, 1.0 + 0.1 * access_count)`
  - Implementado em `src/core/decay_service.py`
- [x] **14.3** Cron job semanal para arquivar entries com score < 0.05
  - Handler: `src/engine/decay_handlers.py` ‚Üí `on_decay_archiving_triggered`
  - Agendado em `lifespan()` via `_schedule_decay_archiving(cron_scheduler)` (every 168h)
  - `semantic_search()` atualizado: filtra `archived=FALSE`, re-rank por `final_score`, fire-and-forget `record_access()`
- [x] **14.4** Testes E2E ‚Äî 18/18 passando (`TestFase14TemporalDecay`)
- [ ] **14.5** Testar em produ√ß√£o (deploy autom√°tico via push)

---

## FASE 15 ‚Äî Contradiction Detection ‚úÖ CONCLU√çDA

**Objetivo:** Detectar quando novo conhecimento contradiz conhecimento existente.
**Por qu√™:** Sem detec√ß√£o, agente pode ter informa√ß√µes conflitantes e dar respostas inconsistentes.
**Ref:** `agent-claude.md` se√ß√£o "Contradiction Detection"

- [x] **15.1** Ao salvar novo knowledge, buscar top-5 similares (coseno >= 0.8)
  - `contradiction_service._find_similar()` ‚Üí `embedding_service.semantic_search(threshold=0.8)`
- [x] **15.2** LLM classifica rela√ß√£o: `complementary | update | contradiction`
  - Prompt para `LLM_FALLBACK_MODEL` (Gemini Flash) ‚Üí parse `CLASSIFICACAO | explicacao`
  - Graceful fallback: se LLM falhar ‚Üí retorna `None` (nao bloqueia o save)
  - Implementado em `src/core/contradiction_service.py`
- [x] **15.3** Se contradiction: HTTP 409 com detalhes; `force=True` bypassa
  - Call path: `async_share(force=False)` ‚Üí `contradiction_service.check()` ‚Üí `raise ContradictionDetected` ‚Üí `knowledge.py` ‚Üí HTTP 409
  - `POST /api/v1/knowledge/share?force=true` para salvar mesmo assim
- [x] **15.4** Testes E2E ‚Äî 14/14 passando (`TestFase15ContradictionDetection`)
- [ ] **15.5** Testar em producao (deploy automatico via push)

---

## FASE 16 ‚Äî Proactive Insights

**Objetivo:** Agente sugere a√ß√µes baseado em padr√µes detectados (n√£o apenas responde).
**Por qu√™:** Transforma o agente de reativo para proativo ‚Äî diferencial competitivo.
**Ref:** `agent-claude.md` se√ß√£o "Proactive"

- [ ] **16.1** Conectar `proactive_researcher.py` ao cron (1x/dia)
  - Call path: `cron_scheduler` ‚Üí `proactive_researcher.check_patterns()` ‚Üí `notification_service.notify()`
- [ ] **16.2** Fonte de dados: emails recentes, tarefas pendentes, calendar
- [ ] **16.3** Apresentar como "suggestion chips" no frontend
- [ ] **16.4** Testes E2E
- [ ] **16.5** Testar em produ√ß√£o

---

## FASE 17 ‚Äî Prompt Engineering Avan√ßado

**Objetivo:** Aplicar t√©cnicas de `prompt-avancado.md` e `Prompt-COT.md` no system prompt e ReAct loop.
**Por qu√™:** Melhora qualidade das respostas sem custo de infra.

- [ ] **17.1** Chain-of-Thought expl√≠cito no system prompt dos agents
  - Adicionar instru√ß√£o "Pense passo a passo antes de responder" no SOUL.md template
- [ ] **17.2** Few-shot examples no prompt de tools complexas (db_query, browser)
- [ ] **17.3** Output primers ‚Äî terminar prompt com in√≠cio da resposta esperada
- [ ] **17.4** Delimiters claros (###, ```) para separar contexto/instru√ß√£o/exemplos
- [ ] **17.5** Validar melhoria com testes A/B em produ√ß√£o (comparar respostas antes/depois)

---

## FASE 18 ‚Äî User Profile & Settings Completo

**Objetivo:** Completar perfil do usu√°rio com avatar, prefer√™ncias e configura√ß√µes do agente.
**Por qu√™:** `planning-optimus.md` item 2 ‚Äî onboarding personalizado.

- [ ] **18.1** Avatar upload (Gravatar fallback)
- [ ] **18.2** Altera√ß√£o de senha
- [ ] **18.3** Configura√ß√µes do agente: nome, tom de voz, idioma preferido
- [ ] **18.4** Persistir prefer√™ncias no PostgreSQL (tabela `user_preferences`)
- [ ] **18.5** Carregar prefer√™ncias no session bootstrap
- [ ] **18.6** Testes E2E + produ√ß√£o

---

## FASE 19 ‚Äî VPS & PWA (Completar)

**Objetivo:** Finalizar deploy em VPS pr√≥prio e PWA para mobile.
**Por qu√™:** `roadmap-optimus-v2.md` FASE 7 ‚Äî parcialmente conclu√≠do.
**Ref:** `planning-optimus.md` item 7 ‚Äî "estar em todo lugar"

- [ ] **19.1** PWA manifest + service worker para cache offline
- [ ] **19.2** Push notifications via web push API
- [ ] **19.3** Testar instala√ß√£o PWA em Android e iOS
- [ ] **19.4** Otimizar para mobile (responsive, touch-friendly)

---

## FASE 20 ‚Äî Browser Streaming (Completar)

**Objetivo:** Streaming visual do browser automation para o usu√°rio.
**Por qu√™:** `roadmap-optimus-v2.md` FASE 2C ‚Äî planejado mas n√£o implementado.

- [ ] **20.1** CDP screenshots peri√≥dicos durante navega√ß√£o
- [ ] **20.2** Stream via SSE para o frontend
- [ ] **20.3** UI: janela de preview do browser no chat
- [ ] **20.4** Testes E2E + produ√ß√£o

---

## FASE 21 ‚Äî Integra√ß√£o de M√≥dulos √ìrf√£os ‚úÖ PARCIAL

**Objetivo:** Integrar m√≥dulos que existiam mas n√£o eram chamados no fluxo real.
**An√°lise (2026-02-19):** Diagn√≥stico inicial estava errado ‚Äî nenhum m√≥dulo deve ser deletado. Todos t√™m valor, precisavam apenas ser conectados.

### Diagn√≥stico real por m√≥dulo:

| M√≥dulo | Status Real | Integra√ß√£o | Pr√≥xima A√ß√£o |
|--------|-------------|-----------|--------------|
| `intent_classifier.py` | ‚úÖ Integrado 100% | gateway.py:191 + smart routing FASE 21 | Nenhuma |
| `intent_predictor.py` | ‚úÖ Integrado 80% | gateway.py: prediction chips na resposta | Frontend renderizar suggestions |
| `autonomous_executor.py` | ‚úÖ Integrado 100% | react_loop.py:277-303 | Nenhuma |
| `rag.py` | ‚úÖ Integrado 80% | gateway.py: auto-context para research/analysis | Auto-ingest de uploads |
| `webchat.py` | ‚úÖ Integrado 100% | main.py:227, APIs 583-642 | Nenhuma |
| `voice_interface.py` | ‚úÖ Integrado 100% | api/voice.py (todos endpoints) | Nenhuma |
| `reflection_engine.py` | ‚ö†Ô∏è 0% | Nunca chamado | INTEGRAR: cron semanal |
| `working_memory.py` | ‚ö†Ô∏è 0% | Nunca chamado | INTEGRAR: session context |
| `tools_manifest.py` | ‚ö†Ô∏è 0% | Nunca chamado | INTEGRAR: startup |
| `cron_scheduler.py` | ‚ö†Ô∏è 0% | Framework sem jobs | INTEGRAR: registrar jobs |
| `context_awareness.py` | ‚ö†Ô∏è 0% | Nunca chamado | INTEGRAR: session bootstrap |
| `security.py` | ‚ö†Ô∏è 20% | Import mas sem enforcement | INTEGRAR: gateway |

### O que foi integrado nesta sess√£o (2026-02-19):
- [x] **21.1** `intent_classifier.py` ‚Äî Smart routing: quando confidence > 0.5, mensagens de code ‚Üí `friday`, research ‚Üí `fury`
  - Call path: `gateway.route_message()` linha ~283 ‚Üí `AgentFactory.get(suggested_agent)`
- [x] **21.2** `intent_predictor.py` ‚Äî Suggestion chips: padr√µes aprendidos viram sugest√µes proativas na resposta
  - Call path: `gateway.route_message()` linha ~340 ‚Üí `predict_next()` ‚Üí `result["suggestions"]`
- [x] **21.3** `rag.py` ‚Äî RAG auto-context: queries de research/analysis enriquecem contexto automaticamente
  - Call path: `gateway.route_message()` linha ~261 ‚Üí `rag_pipeline.augment_prompt()` ‚Üí `context["rag_context"]`
  - Renderizado pelo `react_loop.py` em `_build_user_content()`

### Tamb√©m j√° integrados (descobertos nesta sess√£o):
- [x] **21.4** `reflection_engine.py` ‚Äî J√Å INTEGRADO (main.py:184 ‚Üí reflection_handlers.py ‚Üí cron weekly_reflection)
- [x] **21.6** `tools_manifest.py` ‚Äî M√≥dulo n√£o existe; ignorado
- [x] **21.8** `security.py` ‚Äî J√Å INTEGRADO (react_loop.py:252 ‚Üí check_permission(MCP_EXECUTE) por tool call)

### Integrado nesta sess√£o (itens 21.5, 21.7, 21.9):
- [x] **21.5** `working_memory.py` ‚Äî WORKING.md carregado em `context["working_memory"]` no gateway
  - Call path: `gateway.route_message()` ‚Üí `wm_service.load(agent_name)` ‚Üí `context["working_memory"]`
  - react_loop.py `_build_user_content()` j√° injetava se presente (checkpoint‚úì)
- [x] **21.7** `context_awareness.py` ‚Äî Contexto de tempo/dia injetado em `context["time_context"]`
  - Call path: `gateway.route_message()` ‚Üí `ContextAwareness().build_context()` ‚Üí `context["time_context"]`
  - Injetado no prompt via react_loop.py `_build_user_content()` como linha de contexto
  - Exemplo: `[Boa tarde, 14:30 ‚Äî sexta-feira. Sexta-feira! üéâ Vamos fechar a semana. Algo para deploy?]`
- [x] **21.9** Frontend: chips renderizados ap√≥s cada resposta que inclua `suggestions`
  - `data?.data?.suggestions` ‚Üí `renderSuggestionChips()` ‚Üí chips clic√°veis preenchem o input

## FASE 21 ‚Äî ‚úÖ CONCLU√çDA (2026-02-19)

---

## FASE 22 ‚Äî Redis Otimizado

**Objetivo:** Usar Redis para o que foi projetado ‚Äî session cache e pub/sub.
**Por qu√™:** Redis est√° conectado mas subutilizado (s√≥ rate limiting).

- [ ] **22.1** Session cache: √∫ltimas 5 sess√µes ativas no Redis (TTL 30min)
- [ ] **22.2** Pub/Sub para notifica√ß√µes real-time entre workers
- [ ] **22.3** Cache de embeddings frequentes (top 100 queries)
- [ ] **22.4** Testes E2E + produ√ß√£o

---

## FASE 23 ‚Äî Acesso √† M√°quina do Usu√°rio

**Objetivo:** Permitir que o agente interaja com o computador do usu√°rio (com autoriza√ß√£o).
**Por qu√™:** `planning-optimus.md` item 5 ‚Äî "ter acesso a tudo".

- [ ] **23.1** Avaliar arquitetura: CLI local + API bridge vs browser extension
- [ ] **23.2** MVP: CLI que conecta ao AgentOptimus via WebSocket
- [ ] **23.3** Permiss√µes granulares (filesystem read, write, execute)
- [ ] **23.4** Sandbox de seguran√ßa (whitelist de comandos/paths)
- [ ] **23.5** Testes controlados antes de produ√ß√£o

---

## FASE 24 ‚Äî Voice Assistant (Alexa/Siri-like)

**Objetivo:** Wake word + voice always-on.
**Por qu√™:** `planning-optimus.md` item 6 ‚Äî "funcionar como Alexa/Siri".

- [ ] **24.1** Wake word detection no frontend (Web Speech API ou Picovoice)
- [ ] **24.2** Modo "always listening" com indicador visual
- [ ] **24.3** Resposta por voz autom√°tica (sem precisar clicar)
- [ ] **24.4** Testes em Chrome/Firefox/Safari

---

## FASE 25 ‚Äî Intelligence Engine Real (ToT + Uncertainty)

**Objetivo:** Conectar `tot_engine.py` e `uncertainty.py` ao fluxo real de conversas.
**Por qu√™:** Ambos existem mas nunca s√£o chamados. Estado Atual marcava como ‚úÖ mas s√£o stubs funcionais sem integra√ß√£o real.
**Evid√™ncia do gap:** `roadmap-optimus-v2.md` Bloco 5 ‚Äî "NUNCA chamado. Nenhum agente chama think() durante conversa real."

- [ ] **25.1** Conectar `tot_engine.think()` ao `react_loop.py` para queries marcadas como complexas
  - Call path: `react_loop.process()` ‚Üí detecta query complexa ‚Üí `tot_service.think(query)` ‚Üí injeta pre-reasoning no prompt
  - Crit√©rio de ativa√ß√£o: `is_complex_query()` j√° existe em `react_loop.py`
- [ ] **25.2** Substituir heur√≠stica de uncertainty pelo `UncertaintyQuantifier` real
  - Call path: `gateway.route_message()` ‚Üí resposta gerada ‚Üí `uncertainty.quantify(response, context)` ‚Üí score real
  - Se score > threshold ‚Üí adicionar üî¥ warning (atualmente calculado por regex simples)
- [ ] **25.3** Testes E2E ‚Äî `TestFase25IntelligenceReal`
- [ ] **25.4** Testar em produ√ß√£o

---

## FASE 26 ‚Äî Web Research Real (Tavily)

**Objetivo:** Substituir o stub `research_search` por chamada real √† API Tavily.
**Por qu√™:** `research_search` em `mcp_tools.py` retorna mock. Estado Atual marcava "Web Research (Tavily) ‚úÖ" incorretamente.
**Evid√™ncia do gap:** `roadmap-optimus-v2.md` Bloco 6 ‚Äî "research ‚ùå √â um stub. Nenhuma API real integrada."

- [ ] **26.1** Integrar Tavily API em `mcp_tools.py`
  - Call path: `react_loop` ‚Üí tool `research_search(query)` ‚Üí `tavily_client.search(query)` ‚Üí resultados reais
  - Graceful fallback: sem `TAVILY_API_KEY` ‚Üí log warning + retorna mock (comportamento atual)
- [ ] **26.2** Adicionar `TAVILY_API_KEY` ao `config.py` e ao Coolify
- [ ] **26.3** Testes E2E ‚Äî `TestFase26WebResearch`
- [ ] **26.4** Testar em produ√ß√£o

---

## FASE 27 ‚Äî Agentic RAG Nativo

**Objetivo:** Conectar `rag.py` ao fluxo principal de forma transparente.
**Por qu√™:** `rag.py` existe e foi parcialmente conectado (FASE 21), mas o fluxo ainda usa `knowledge_tool` separado. O RAG deveria enriquecer automaticamente o contexto de qualquer query relevante.
**Evid√™ncia do gap:** `roadmap-optimus-v2.md` Bloco 4 ‚Äî "Agentic RAG ‚ö†Ô∏è Parcial ‚Äî rag.py existe mas √© √≥rf√£o."

- [ ] **27.1** Auto-ingest de uploads: ao receber PDF/CSV via multimodal, indexar automaticamente no PGvector
  - Call path: `files_service.process()` ‚Üí `rag_pipeline.ingest(content, source)` ‚Üí `embedding_service.store_embedding()`
- [ ] **27.2** Garantir que RAG augmentation est√° ativa para todos os intents relevantes (research, analysis, qa)
  - Verificar integra√ß√£o existente de FASE 21 e corrigir se necess√°rio
- [ ] **27.3** Testes E2E ‚Äî `TestFase27RAGNativo`
- [ ] **27.4** Testar em produ√ß√£o

---

## FASE 28 ‚Äî Plugins MCP & Skills Auto-install

**Objetivo:** Ativar o sistema de plugins MCP e o auto-install de skills.
**Por qu√™:** `workspace/plugins/` est√° vazia. `skills_discovery.py` faz busca mas n√£o instala. `tools_manifest.py` nunca gera TOOLS.md.
**Evid√™ncia do gap:** `roadmap-optimus-v2.md` Bloco 6 ‚Äî "Plugin MCP ‚ùå pasta vazia. Skills auto-install ‚ùå."

- [ ] **28.1** Criar pelo menos 1 plugin MCP de exemplo em `workspace/plugins/`
  - Estrutura: arquivo `.py` com `def register_tools() -> list[MCPTool]:`
  - Call path: `main.py startup` ‚Üí `mcp_plugin.load_plugins()` ‚Üí tools registradas no registry
- [ ] **28.2** Gerar `workspace/TOOLS.md` via `tools_manifest.py` no startup
  - Call path: `main.py startup` ‚Üí `tools_manifest.generate()` ‚Üí `workspace/TOOLS.md` (lista de tools dispon√≠veis)
- [ ] **28.3** `skills_discovery.py` ‚Äî ao encontrar skill compat√≠vel, instalar automaticamente (com confirma√ß√£o do usu√°rio)
- [ ] **28.4** Testes E2E ‚Äî `TestFase28Plugins`
- [ ] **28.5** Testar em produ√ß√£o

---

## FASE 29 ‚Äî Webhooks & Presence

**Objetivo:** Receber eventos externos (GitHub, Forms) e implementar status de presen√ßa.
**Por qu√™:** Nenhum WebhookReceiver ativo. Presence (online/offline) n√£o existe.
**Evid√™ncia do gap:** `roadmap-optimus-v2.md` Bloco 1 ‚Äî "Webhooks ‚ùå". Bloco 2 ‚Äî "Presence ‚ùå."

- [ ] **29.1** Webhook receiver gen√©rico
  - Call path: `POST /api/v1/webhooks/{source}` ‚Üí valida secret ‚Üí `event_bus.emit(WEBHOOK_RECEIVED, payload)` ‚Üí handler processa
  - Sources iniciais: `github` (push/PR events), `generic` (qualquer JSON)
- [ ] **29.2** Presence: status online/offline por usu√°rio
  - SSE heartbeat a cada 30s ‚Üí atualiza `last_seen` no Redis (TTL 60s) ‚Üí `GET /api/v1/presence/{user_id}`
- [ ] **29.3** Testes E2E ‚Äî `TestFase29Webhooks`
- [ ] **29.4** Testar em produ√ß√£o

---

## FASE 30 ‚Äî Eval CI & Debug Web UI

**Objetivo:** Integrar `eval_runner.py` ao CI e construir painel de debug da orquestra√ß√£o.
**Por qu√™:** `eval_runner.py` existe mas n√£o est√° no CI. Debug Web UI prometido pelo Google ADK nunca foi constru√≠do.
**Evid√™ncia do gap:** `roadmap-optimus-v2.md` Bloco 3 ‚Äî "Evaluation ‚ö†Ô∏è Parcial. Debug Web UI ‚ùå."

- [ ] **30.1** Integrar `eval_runner.py` ao pipeline CI (GitHub Actions ou Coolify hooks)
  - Rodar suite de avalia√ß√£o a cada push para `main`
  - M√©tricas: acur√°cia de tool calling, taxa de fallback, lat√™ncia P95
- [ ] **30.2** Debug Web UI ‚Äî painel em `/debug` (protegido por auth admin)
  - Visualizar: pipelines de orquestra√ß√£o ativos, fila de cron jobs, √∫ltimas 10 sess√µes de audit
  - Dados j√° existem: `audit_log`, `cron_scheduler.list_jobs()`, `decay_service.get_stats()`
- [ ] **30.3** Testes E2E ‚Äî `TestFase30EvalDebug`
- [ ] **30.4** Testar em produ√ß√£o

---

## Prioriza√ß√£o Recomendada

| Prioridade | Fase | Impacto | Esfor√ßo |
|-----------|------|---------|---------|
| **P0** | FASE 10 ‚Äî Chat Commands | Alto (funcionalidade existente, s√≥ conectar) | Baixo |
| **P0** | FASE 21 ‚Äî Limpeza C√≥digo Morto | Alto (reduz complexidade) | M√©dio |
| **P1** | FASE 12 ‚Äî Audit Trail | Alto (debug + melhoria cont√≠nua) | M√©dio |
| **P1** | FASE 13 ‚Äî Embeddings CI | Alto (qualidade do knowledge) | Baixo |
| **P1** | FASE 25 ‚Äî Intelligence Real (ToT+Uncertainty) | Alto (corrige falso ‚úÖ, impacto direto na qualidade) | M√©dio |
| **P1** | FASE 26 ‚Äî Web Research Real (Tavily) | Alto (corrige falso ‚úÖ, pesquisa funcional) | Baixo |
| **P1** | FASE 17 ‚Äî Prompt Engineering | Alto (qualidade sem custo) | Baixo |
| **P2** | FASE 27 ‚Äî Agentic RAG Nativo | Alto (uploads indexados automaticamente) | M√©dio |
| **P2** | FASE 14 ‚Äî Temporal Decay | M√©dio (relev√¢ncia da mem√≥ria) | M√©dio |
| **P2** | FASE 18 ‚Äî User Profile | M√©dio (UX) | Baixo |
| **P2** | FASE 19 ‚Äî PWA | M√©dio (mobile access) | M√©dio |
| **P2** | FASE 11 ‚Äî Telegram | M√©dio (novo canal) | M√©dio |
| **P3** | FASE 15 ‚Äî Contradiction | M√©dio (consist√™ncia) | M√©dio |
| **P3** | FASE 16 ‚Äî Proactive | Alto (diferencial) | Alto |
| **P3** | FASE 28 ‚Äî Plugins MCP & Skills | M√©dio (extensibilidade) | M√©dio |
| **P3** | FASE 29 ‚Äî Webhooks & Presence | M√©dio (integra√ß√µes externas) | M√©dio |
| **P3** | FASE 20 ‚Äî Browser Streaming | Baixo (nice-to-have) | M√©dio |
| **P3** | FASE 22 ‚Äî Redis | M√©dio (performance) | M√©dio |
| **P4** | FASE 30 ‚Äî Eval CI & Debug UI | M√©dio (qualidade de engenharia) | M√©dio |
| **P4** | FASE 23 ‚Äî M√°quina do Usu√°rio | Alto (ambicioso) | Alto |
| **P4** | FASE 24 ‚Äî Voice Assistant | M√©dio (UX avan√ßado) | Alto |

---

## Decis√µes Arquiteturais (N√ÉO fazer)

| Proposta | Decis√£o | Motivo |
|----------|---------|--------|
| Migrar para Google ADK | **N√ÉO** | Implementa√ß√£o custom √© feature-complete, migra√ß√£o seria rewrite sem valor |
| Migrar para Agno | **N√ÉO** | Mesmo motivo. AgentFactory + BaseAgent atendem. |
| Graph DB (Neo4j) | **N√ÉO** | PostgreSQL + PGvector resolve. Complexidade n√£o justificada. |
| Self-hosted LLM | **N√ÉO** | Custo de GPU > custo de API. Sem escala que justifique. |
| LangChain/LangGraph | **N√ÉO** | ReAct loop custom funciona. Adicionar framework = depend√™ncia sem ganho. |
| Supabase Realtime | **AVALIAR DEPOIS** | S√≥ se polling se tornar gargalo mensur√°vel. |

---

## Refer√™ncias

- [planning-optimus.md](.docs/planning-optimus.md) ‚Äî Vis√£o do usu√°rio e requisitos de produto
- [Roadmap-Optimus.md](.docs/Roadmap-Optimus.md) ‚Äî Roadmap original (fases 1-23) + Regra de Ouro + Diagn√≥stico
- [roadmap-optimus-v2.md](.docs/roadmap-optimus-v2.md) ‚Äî Roadmap v2 detalhado (FASE 0-9) + An√°lise de gaps
- [agent-claude.md](.docs/agent-claude.md) ‚Äî Pesquisa de arquitetura + recomenda√ß√µes t√©cnicas
- [prompt-avancado.md](.docs/prompt-avancado.md) ‚Äî T√©cnica Syntopic Reading para prompts
- [Prompt-COT.md](.docs/Prompt-COT.md) ‚Äî 26 princ√≠pios de prompt engineering
